# ðŸ§  Image Classification with CNN â€” CIFAR-10

![Python](https://img.shields.io/badge/Python-3.x-blue?logo=python)
![TensorFlow](https://img.shields.io/badge/TensorFlow-2.x-orange?logo=tensorflow)
![Keras](https://img.shields.io/badge/Keras-Deep%20Learning-red?logo=keras)
![Dataset](https://img.shields.io/badge/Dataset-CIFAR--10-green)

## ðŸ“Œ Project Overview

This project implements a **Convolutional Neural Network (CNN)** for automatic image classification using the **CIFAR-10** dataset. The model is capable of identifying 10 object categories with high accuracy, leveraging modern regularization techniques and data augmentation to optimize performance.

## ðŸŽ¯ Objective

Design and train a computer vision model using a deep CNN architecture, evaluating its generalization capability on unseen images from the CIFAR-10 benchmark dataset.

## ðŸ—‚ï¸ Dataset Classes

| ID | Class        |
|----|--------------|
| 0  | Airplane âœˆï¸  |
| 1  | Automobile ðŸš— |
| 2  | Bird ðŸ¦      |
| 3  | Cat ðŸ±       |
| 4  | Deer ðŸ¦Œ      |
| 5  | Dog ðŸ¶       |
| 6  | Frog ðŸ¸      |
| 7  | Horse ðŸ´     |
| 8  | Ship ðŸš¢      |
| 9  | Truck ðŸšš     |

## ðŸ—ï¸ Model Architecture

The CNN is inspired by the **VGG-Net** architecture, featuring three convolutional blocks with progressively larger filters (64 â†’ 128 â†’ 256), followed by fully connected dense layers.

Each block includes:
- Two `Conv2D` layers with `ReLU` activation and `He Normal` initialization
- `L2` regularization to reduce overfitting
- A `MaxPooling` layer for dimensionality reduction
- `BatchNormalization` to stabilize training

The output layer uses `Softmax` for multi-class classification across the **10 CIFAR-10 categories**.

**Total parameters:** ~1.68 million

## âš™ï¸ Training Configuration

| Parameter        | Value                          |
|-----------------|-------------------------------|
| Optimizer        | Adam                           |
| Learning Rate    | 0.0001                         |
| Loss Function    | Sparse Categorical Crossentropy |
| Regularization   | L2 (0.001)                     |
| Initialization   | He Normal                      |
| Callbacks        | EarlyStopping                  |

## ðŸ”§ Techniques Applied

- âœ… **Batch Normalization** â€” stabilizes and accelerates training
- âœ… **Dropout** â€” reduces overfitting (rates: 0.2 and 0.3)
- âœ… **L2 Regularization** â€” penalizes large weights
- âœ… **Data Augmentation** â€” rotation, horizontal flip, zoom, and shift
- âœ… **EarlyStopping** â€” halts training when validation loss stops improving

## ðŸ“ Project Structure

```
ðŸ“¦ CNN-CIFAR10
 â”£ ðŸ““ Vision por computador Cifar10.ipynb   â† Main notebook
 â”£ ðŸ“„ README.md                              â† This file
```

## ðŸš€ Getting Started

1. Clone the repository:
   ```bash
   git clone https://github.com/YOUR_USERNAME/YOUR_REPO.git
   ```

2. Install dependencies:
   ```bash
   pip install tensorflow numpy matplotlib
   ```

3. Open the notebook:
   ```bash
   jupyter notebook "Vision por computador Cifar10.ipynb"
   ```

4. Run cells in order.

## ðŸ“¦ Requirements

```
tensorflow >= 2.0
numpy
matplotlib
```

## ðŸ‘¤ Author

**Gianpier Giandoni**
Project developed as part of the **Computer Vision** course at [Nuclio Digital School](https://nuclio.school).
